{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<spacy_langdetect.spacy_langdetect.LanguageDetector at 0x13b28fee0>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from lxml import etree\n",
    "from lxml.etree import XMLSyntaxError\n",
    "from spacy import Language\n",
    "from spacy_langdetect import LanguageDetector\n",
    "\n",
    "\n",
    "@Language.factory('language_detector')\n",
    "def language_detector(nlp, name):\n",
    "    return LanguageDetector()\n",
    "\n",
    "\n",
    "NLP = spacy.load('de_core_news_sm')\n",
    "NLP.add_pipe('language_detector')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NAMESPACE: dict = {'tei': 'http://www.tei-c.org/ns/1.0'}\n",
    "SAVINGS_PATH: str = '../data/plain-text/'\n",
    "\n",
    "if not os.path.exists(SAVINGS_PATH):\n",
    "    os.makedirs(SAVINGS_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def get_letter_text(path: str ='../data/*.xml') -> None:\n",
    "    \"\"\"Function for extracting and cleaning text from the XML/TEI letter files.\n",
    "\n",
    "    :param path: File path given as string.\n",
    "    :return: None.\n",
    "    \"\"\"\n",
    "    for file in glob.glob(pathname=path)[:]:\n",
    "        try:\n",
    "            tree = etree.parse(file)\n",
    "\n",
    "            letter_output: str = \"\"\n",
    "\n",
    "            for text in tree.xpath('//tei:text//tei:body//text()', namespaces=NAMESPACE):\n",
    "                text = text.lower()\n",
    "                # Remove any expressions of type \"[HERE NUMBER]\" from the text.\n",
    "                if re.match(r'.*\\[.*].*', text):\n",
    "                    letter_output += re.sub(r'\\[.*]', '', text) + ' '\n",
    "                # Remove the given statements from the text as they are not needed for performing SA.\n",
    "                elif 'beyliegendes von' or 'paginierung des editors' in text:\n",
    "                    letter_output += re.sub(r'beyliegendes von|paginierung des editors', '', text) + ' '\n",
    "                # Remove any dates (except for dates in words, e.g. \"14. Februar 1833\").\n",
    "                else:\n",
    "                    letter_output += re.sub(r'^(0[1-9]|[12][0-9]|3[01])[.](0[1-9]|1[012])[.](19|20)[0-9]{2}', ' ',\n",
    "                                            text) + ' '\n",
    "\n",
    "            # Remove unnecessary whitespace and any further characters that are neither alphanumerical nor (singular) whitespace.\n",
    "            letter_output = re.sub('\\s{2,}', ' ', letter_output.lstrip())\n",
    "            letter_output = re.sub('[^\\w\\s\\d]|_', '', letter_output)\n",
    "\n",
    "            \"\"\"Using spaCy's available pipe for language detection to store only German letters. I also tried out to do this before preprocessing the texts but this lead to some major issues.\n",
    "            \"\"\"\n",
    "            doc = NLP(letter_output)\n",
    "            if doc._.language['language'] == 'de':\n",
    "                with open(SAVINGS_PATH + re.sub(r'\\.xml', '.txt', os.path.basename(file)), 'w') as f_tbw:\n",
    "                    f_tbw.write(letter_output)\n",
    "\n",
    "        except XMLSyntaxError:\n",
    "            pass\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "get_letter_text()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from textblob_de import TextBlobDE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "sentiment_dict: dict = {}\n",
    "\n",
    "for file in glob.glob('../data/plain-text/*.txt')[:]:\n",
    "    with open(file, 'r') as f:\n",
    "        text = f.read()\n",
    "        letter_blob = TextBlobDE(text)\n",
    "        sentiment_dict[os.path.basename(file)] = letter_blob.sentiment\n",
    "\n",
    "s_df = pd.DataFrame.from_dict(sentiment_dict).transpose()\n",
    "s_df.index.names = ['filename']\n",
    "s_df.rename(columns={0: 'polarity', 1: 'subjectivity'}, inplace=True)\n",
    "s_df.to_csv('../data/retrieved/sentiments.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}